<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Fischanalyse GUI Pr√§sentation - main.py</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0;
            padding: 20px;
            background-color: #f8f9fa;
            color: #212529;
            line-height: 1.6;
        }
        .container {
            max-width: 1400px;
            margin: 0 auto;
        }
        .header {
            background: linear-gradient(135deg, #ff6b6b 0%, #4ecdc4 100%);
            color: white;
            padding: 40px;
            border-radius: 15px;
            margin-bottom: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
        }
        .header h1 {
            margin: 0 0 10px 0;
            font-size: 2.5em;
            font-weight: 700;
        }
        .header p {
            margin: 0;
            font-size: 1.2em;
            opacity: 0.9;
        }
        .section {
            display: flex;
            gap: 30px;
            margin-bottom: 30px;
            background: white;
            border-radius: 15px;
            overflow: hidden;
            box-shadow: 0 5px 15px rgba(0,0,0,0.08);
        }
        .visual-side {
            flex: 1;
            background: linear-gradient(45deg, #f1f3f4, #e8eaed);
            min-height: 300px;
            display: flex;
            align-items: center;
            justify-content: center;
            color: #5f6368;
            font-size: 1.1em;
            text-align: center;
            position: relative;
            overflow: hidden;
        }
        .visual-side::before {
            content: '';
            position: absolute;
            top: -50%;
            left: -50%;
            width: 200%;
            height: 200%;
            background: url('data:image/svg+xml,<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100"><defs><pattern id="grid" width="10" height="10" patternUnits="userSpaceOnUse"><path d="M 10 0 L 0 0 0 10" fill="none" stroke="%23e0e0e0" stroke-width="0.5"/></pattern></defs><rect width="100" height="100" fill="url(%23grid)"/></svg>') repeat;
            opacity: 0.3;
        }
        .visual-placeholder {
            background: rgba(255,255,255,0.8);
            padding: 20px;
            border-radius: 10px;
            border: 2px dashed #dadce0;
            position: relative;
            z-index: 1;
        }
        .content-side {
            flex: 1;
            padding: 40px;
        }
        h2 {
            color: #1a73e8;
            font-size: 1.8em;
            margin-bottom: 20px;
            font-weight: 600;
            border-bottom: 2px solid #e8f0fe;
            padding-bottom: 10px;
        }
        h3 {
            color: #137333;
            font-size: 1.3em;
            margin-top: 25px;
            margin-bottom: 15px;
            font-weight: 600;
        }
        .tech-term {
            background: #e8f0fe;
            color: #1a73e8;
            padding: 2px 8px;
            border-radius: 4px;
            font-weight: 600;
        }
        .explanation {
            background: #f8f9fa;
            border-left: 4px solid #34a853;
            padding: 15px;
            margin: 15px 0;
            border-radius: 0 8px 8px 0;
        }
        .code-snippet {
            background: #f8f9fa;
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 15px;
            font-family: 'Consolas', 'Monaco', monospace;
            font-size: 0.9em;
            overflow-x: auto;
            margin: 15px 0;
        }
        .highlight {
            background: linear-gradient(120deg, #a8edea 0%, #fed6e3 100%);
            padding: 3px 6px;
            border-radius: 3px;
            font-weight: 600;
        }
        .warning {
            background: #fef7e0;
            border: 1px solid #fbc02d;
            border-radius: 8px;
            padding: 15px;
            margin: 15px 0;
        }
        ul, ol {
            padding-left: 20px;
        }
        li {
            margin-bottom: 8px;
        }
        .badge {
            display: inline-block;
            background: #137333;
            color: white;
            padding: 4px 12px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 600;
            margin: 2px;
        }
        .tab-indicator {
            display: inline-block;
            background: #ff6b6b;
            color: white;
            padding: 6px 14px;
            border-radius: 20px;
            font-size: 0.9em;
            font-weight: 600;
            margin: 3px;
        }
        .model-box {
            background: #e3f2fd;
            border: 2px solid #2196f3;
            border-radius: 10px;
            padding: 15px;
            margin: 10px 0;
        }
        .performance {
            background: #e8f5e8;
            border-left: 4px solid #4caf50;
            padding: 12px;
            margin: 10px 0;
            border-radius: 0 8px 8px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>üê† Fischanalyse GUI Pr√§sentation</h1>
            <p>main.py - Interaktive Demonstration f√ºr Computer Vision Modelle</p>
        </div>

        <div class="section">
            <div class="visual-side">
                <div class="visual-placeholder">
                    <strong>üñ•Ô∏è GUI Layout</strong><br>
                    Visualisierung:<br>
                    ‚Ä¢ Tkinter Tabbed Interface<br>
                    ‚Ä¢ 4 funktionale Tabs<br>
                    ‚Ä¢ Live-Bildanalyse<br>
                    ‚Ä¢ Matplotlib Integration
                </div>
            </div>
            <div class="content-side">
                <h2>üéØ Anwendungs√ºberblick</h2>
                <p>Diese <span class="tech-term">GUI-Anwendung</span> demonstriert drei verschiedene <span class="tech-term">Computer Vision</span> Techniken f√ºr die Unterwasser-Bildanalyse.</p>
                
                <div class="explanation">
                    <strong>GUI (Graphical User Interface):</strong> Eine grafische Benutzeroberfl√§che, die es erm√∂glicht, komplexe KI-Modelle ohne Programmierung zu bedienen - einfach durch Klicken und Drag & Drop.
                </div>

                <h3>üèóÔ∏è Anwendungsarchitektur</h3>
                <ul>
                    <li><span class="tab-indicator">Upload</span> Bildauswahl und RGB-Analyse</li>
                    <li><span class="tab-indicator">Klassifikation</span> ResNet-18 Objektklassifizierung</li>
                    <li><span class="tab-indicator">Objekterkennung</span> YOLOv8 Detection</li>
                    <li><span class="tab-indicator">Segmentierung</span> Pixel-Level Masken</li>
                </ul>

                <div class="performance">
                    <strong>üí° Live-Processing:</strong> Alle drei KI-Modelle werden parallel in separaten Threads ausgef√ºhrt, wodurch die Benutzeroberfl√§che reaktionsf√§hig bleibt und Ergebnisse in Echtzeit angezeigt werden.
                </div>
            </div>
        </div>

        <div class="section">
            <div class="visual-side">
                <div class="visual-placeholder">
                    <strong>üìä Upload & Analyse</strong><br>
                    Visualisierung:<br>
                    ‚Ä¢ Datei-Dialog<br>
                    ‚Ä¢ Bildvorschau (500x500)<br>
                    ‚Ä¢ RGB-Histogramm<br>
                    ‚Ä¢ Threading-Pipeline
                </div>
            </div>
            <div class="content-side">
                <h2>üìÇ Tab 1: Upload & Bildanalyse</h2>
                
                <h3>üñºÔ∏è Bildverarbeitung Pipeline</h3>
                <p>Der Upload-Tab kombiniert <span class="tech-term">Bildvorschau</span> mit statistischer <span class="tech-term">Farbanalyse</span>.</p>
                
                <div class="explanation">
                    <strong>RGB-Histogramm:</strong> Ein Diagramm, das die Verteilung der Rot-, Gr√ºn- und Blauwerte in einem Bild zeigt. Hilft dabei, die Farbcharakteristik und Belichtung zu verstehen.
                </div>

                <div class="code-snippet">
# Automatische Bildgr√∂√üenanpassung
img.thumbnail((500,500))

# RGB-Kanal Separation f√ºr Histogramm
r,g,b = img.split()
ax.hist(np.array(r).flatten(), bins=256, color='r', alpha=0.5)
                </div>

                <h3>‚ö° Parallel Processing</h3>
                <p>Nach dem Upload werden drei <span class="tech-term">Background Threads</span> gestartet:</p>
                
                <ul>
                    <li><span class="highlight">Thread 1:</span> ResNet-18 Klassifikation</li>
                    <li><span class="highlight">Thread 2:</span> YOLO Objekterkennung</li>
                    <li><span class="highlight">Thread 3:</span> Segmentierung (Dummy)</li>
                </ul>
                
                <div class="explanation">
                    <strong>Threading:</strong> Parallel ausgef√ºhrte Programmteile, die es erm√∂glichen, mehrere KI-Modelle gleichzeitig zu berechnen, ohne dass die Benutzeroberfl√§che "einfriert".
                </div>
            </div>
        </div>

        <div class="section">
            <div class="visual-side">
                <div class="visual-placeholder">
                    <strong>üß† ResNet Klassifikation</strong><br>
                    Visualisierung:<br>
                    ‚Ä¢ ResNet-18 Architektur<br>
                    ‚Ä¢ 224x224 Input Preprocessing<br>
                    ‚Ä¢ Softmax Wahrscheinlichkeiten<br>
                    ‚Ä¢ Balkendiagramm Output
                </div>
            </div>
            <div class="content-side">
                <h2>üéØ Tab 2: Deep Learning Klassifikation</h2>
                
                <h3>üèóÔ∏è ResNet-18 Modell</h3>
                <div class="model-box">
                    <strong>Modell:</strong> ResNet-18 mit Transfer Learning<br>
                    <strong>Klassen:</strong> 2 (Riffbarsch, Taucher)<br>
                    <strong>Input:</strong> 224x224 RGB normalisiert<br>
                    <strong>Output:</strong> Wahrscheinlichkeitsverteilung
                </div>
                
                <div class="explanation">
                    <strong>ResNet (Residual Network):</strong> Eine spezielle Art neuronaler Netzwerke mit "Sprungverbindungen", die es erm√∂glichen, sehr tiefe Netzwerke zu trainieren ohne dass die Gradienteninformation verloren geht.
                </div>

                <h3>üîÑ Preprocessing Pipeline</h3>
                <div class="code-snippet">
# Standard ImageNet Normalisierung
transforms.Normalize(
    mean=[0.485, 0.456, 0.406], 
    std=[0.229, 0.224, 0.225]
)
                </div>
                
                <div class="explanation">
                    <strong>Normalisierung:</strong> Anpassung der Pixelwerte auf einen Standardbereich, damit das neuronale Netzwerk optimal lernen kann. Die Werte stammen aus dem ImageNet-Dataset.
                </div>

                <h3>üìä Echzeit-Visualisierung</h3>
                <p>Die <span class="tech-term">Softmax-Wahrscheinlichkeiten</span> werden als interaktives Balkendiagramm dargestellt.</p>
                
                <div class="performance">
                    <strong>‚ö° Performance:</strong> GPU-Unterst√ºtzung aktiviert f√ºr beschleunigte Inferenz mit automatischem CPU-Fallback bei fehlender GPU.
                </div>
            </div>
        </div>

        <div class="section">
            <div class="visual-side">
                <div class="visual-placeholder">
                    <strong>üéØ YOLO Detection</strong><br>
                    Visualisierung:<br>
                    ‚Ä¢ YOLOv8 Architektur<br>
                    ‚Ä¢ Bounding Box Overlay<br>
                    ‚Ä¢ Confidence Scores<br>
                    ‚Ä¢ Box-Gr√∂√üen Analyse
                </div>
            </div>
            <div class="content-side">
                <h2>üîç Tab 3: Objekterkennung (YOLO)</h2>
                
                <h3>‚ö° YOLOv8 Implementation</h3>
                <div class="model-box">
                    <strong>Framework:</strong> Ultralytics YOLOv8n<br>
                    <strong>Task:</strong> Object Detection<br>
                    <strong>Modell:</strong> Custom trained "best.pt"<br>
                    <strong>Output:</strong> Bounding Boxes + Labels
                </div>
                
                <div class="explanation">
                    <strong>YOLO (You Only Look Once):</strong> Ein ultra-schneller Objekterkennungsalgorithmus, der ein Bild nur einmal betrachtet und dabei alle Objekte und ihre Positionen gleichzeitig identifiziert.
                </div>

                <h3>üñºÔ∏è Visualisierung Pipeline</h3>
                <div class="code-snippet">
# YOLO Prediction mit automatischem Overlay
results = yolo_model.predict(img, verbose=False)
result_img = results[0].plot()  # Automatische Box-Visualisierung
                </div>

                <h3>üìà Bounding Box Analyse</h3>
                <p>Zus√§tzlich zur Objekterkennung wird eine statistische Analyse der <span class="tech-term">Bounding Box Dimensionen</span> erstellt.</p>
                
                <div class="explanation">
                    <strong>Bounding Box:</strong> Ein Rechteck, das ein erkanntes Objekt umschlie√üt. Die Gr√∂√üenverteilung gibt Aufschluss √ºber die Objektgr√∂√üen im Bild und kann f√ºr Qualit√§tskontrolle genutzt werden.
                </div>

                <ul>
                    <li><span class="highlight">Breiten-Histogramm:</span> Horizontale Objektausdehnung</li>
                    <li><span class="highlight">H√∂hen-Histogramm:</span> Vertikale Objektausdehnung</li>
                    <li><span class="highlight">√úberlagerung:</span> Vergleich der Dimensionen</li>
                </ul>
            </div>
        </div>

        <div class="section">
            <div class="visual-side">
                <div class="visual-placeholder">
                    <strong>üé® Segmentation Interface</strong><br>
                    Visualisierung:<br>
                    ‚Ä¢ Pixel-Level Masken<br>
                    ‚Ä¢ Alpha-Blending<br>
                    ‚Ä¢ Farbkodierung<br>
                    ‚Ä¢ Fl√§chenberechnung
                </div>
            </div>
            <div class="content-side">
                <h2>‚úÇÔ∏è Tab 4: Segmentierung</h2>
                
                <h3>üé≠ Dummy Segmentierung</h3>
                <p>Aktuell implementiert als <span class="tech-term">Proof of Concept</span> mit simulierten roten Masken.</p>
                
                <div class="explanation">
                    <strong>Segmentierung:</strong> Die pixelgenaue Abgrenzung von Objekten im Bild. Im Gegensatz zu Bounding Boxes wird hier die exakte Form des Objekts erfasst, nicht nur ein umschlie√üendes Rechteck.
                </div>

                <div class="warning">
                    <strong>üîß Entwicklungsstatus:</strong> Dieser Tab zeigt die vorbereitete Infrastruktur f√ºr Mask R-CNN oder SAM-Integration. Die rote Dummy-Maske kann durch echte Segmentierungsmodelle ersetzt werden.
                </div>

                <h3>üé® Alpha-Composite Technik</h3>
                <div class="code-snippet">
# Transparente Masken-√úberlagerung
mask = Image.new("RGBA", img.size, (255,0,0,50))  # 50% Transparenz
img_overlay = Image.alpha_composite(img.convert("RGBA"), mask)
                </div>
                
                <div class="explanation">
                    <strong>Alpha-Compositing:</strong> Eine Bildverarbeitungstechnik, die transparente Ebenen √ºberlagert. Dadurch bleiben das Originalbild und die Segmentierungsmaske gleichzeitig sichtbar.
                </div>

                <h3>üìä Fl√§chenanalyse</h3>
                <p>Berechnung und Visualisierung des <span class="tech-term">segmentierten Fl√§chenanteils</span> als Balkendiagramm.</p>
            </div>
        </div>

        <div class="section">
            <div class="visual-side">
                <div class="visual-placeholder">
                    <strong>‚öôÔ∏è Technical Stack</strong><br>
                    Visualisierung:<br>
                    ‚Ä¢ PyTorch + Torchvision<br>
                    ‚Ä¢ Tkinter GUI Framework<br>
                    ‚Ä¢ Matplotlib Plotting<br>
                    ‚Ä¢ PIL Bildverarbeitung
                </div>
            </div>
            <div class="content-side">
                <h2>üõ†Ô∏è Technische Implementation</h2>
                
                <h3>üì¶ Dependency Stack</h3>
                <ul>
                    <li><span class="badge">PyTorch</span> Deep Learning Framework</li>
                    <li><span class="badge">Torchvision</span> Computer Vision Modelle</li>
                    <li><span class="badge">Tkinter</span> Native GUI Framework</li>
                    <li><span class="badge">PIL/Pillow</span> Bildverarbeitung</li>
                    <li><span class="badge">Matplotlib</span> Wissenschaftliche Plots</li>
                    <li><span class="badge">Ultralytics</span> YOLO Implementation</li>
                </ul>
                
                <h3>üîß Modell-Pfade Konfiguration</h3>
                <div class="code-snippet">
# Zentrale Modell-Registry
RESNET_PATH = "models/resnet/fisch_v2_Z30_20250924_0727_resnet.pt"
YOLO_PATH = "models/yolov8n/riffbarsch_taucher_run/best.pt"  
MASK_PATH = "models/sam_vit/mask_model.pth"
                </div>

                <h3>üéõÔ∏è User Experience Features</h3>
                <ul>
                    <li><span class="highlight">Progress Bars:</span> Visuelle Feedback f√ºr Modell-Berechnungen</li>
                    <li><span class="highlight">Responsive UI:</span> Threading verhindert UI-Blockierung</li>
                    <li><span class="highlight">Live Updates:</span> Ergebnisse werden in Echtzeit angezeigt</li>
                    <li><span class="highlight">Multi-Modal:</span> Drei verschiedene KI-Techniken parallel</li>
                </ul>

                <div class="performance">
                    <strong>üöÄ Deployment Ready:</strong> Standalone-Anwendung mit automatischer Hardware-Detection (GPU/CPU) und integriertem Error-Handling f√ºr Demo-Umgebungen.
                </div>
            </div>
        </div>
    </div>
</body>
</html>